#!/usr/bin/env python3
"""
Test complete recovery pipeline with file saving
"""

import sys
import os
import json
from datetime import datetime

# Add main directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_complete_recovery_with_files():
    """Test recovery with actual file saving in organized structure"""

    print("=== COMPLETE RECOVERY PIPELINE TEST ===\n")

    # Import here to avoid circular imports
    from main import RecoveryReplanAgent, EvaluatorAgent

    # Create agents
    recovery_agent = RecoveryReplanAgent()
    evaluator_agent = EvaluatorAgent()

    # Create timestamp for file organization
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    print(f"Test timestamp: {timestamp}")

    # Create directories
    os.makedirs("data/intermediate", exist_ok=True)
    os.makedirs("data/evaluations", exist_ok=True)
    os.makedirs("data/evidence", exist_ok=True)

    # Mock low-quality evaluation data to trigger recovery
    low_quality_evaluation = {
        "scores": {
            "coverage": 2,      # Low
            "faithfulness": 3,  # Below ideal
            "balance": 1,       # Very low
            "recency": 0,       # No recent sources
            "actionability": 4,
            "readability": 5
        },
        "priority_fixes": [
            "Add more 2024-2025 sources and highlight recent developments",
            "Include more diverse perspectives and systematic reviews",
            "Address bias toward negative findings"
        ],
        "overall_score": 2.5,   # Below 4.0 threshold
        "evaluation_summary": "Poor report quality requiring recovery"
    }

    # Mock compression result with gaps
    compression_result = {
        "key_findings": [
            "Limited evidence for health benefits [0,1]",
            "Strong evidence for health risks [2,3,4]",
            "Research methodology gaps identified [5]"
        ],
        "conflicts": [
            {
                "claim": "Ultra-processed foods health benefits exist",
                "positions": [
                    {"stance": "minimal benefits", "evidence_refs": [0,1]},
                    {"stance": "no benefits", "evidence_refs": [2,3,4]}
                ],
                "explanation": "Different methodologies and study populations"
            }
        ],
        "gaps": [
            "Need more 2024-2025 research on ultra-processed foods",
            "Need comprehensive systematic review of recent evidence",
            "Need research across different age groups",
            "Need long-term longitudinal studies"
        ],
        "coverage_stats": {
            "domains_covered": ["health", "nutrition"],
            "source_types": ["academic", "government"],
            "quality_distribution": {"high": 5, "medium": 3, "low": 2}
        }
    }

    query = "Compare 2024-2025 evidence on ultra-processed foods and recommendations"

    print("1. Creating recovery replan...")
    replan_spec = recovery_agent.create_replan(
        compression_result,
        low_quality_evaluation,
        query
    )

    print(f"   âœ“ Generated {len(replan_spec.get('replan', []))} recovery queries")
    print(f"   âœ“ Trigger: {replan_spec.get('trigger_reason', 'N/A')}")
    print(f"   âœ“ Expected gain: {replan_spec.get('expected_gain', 'N/A')[:100]}...")

    # Save replan specification
    replan_filename = f"data/intermediate/replan_spec_{timestamp}.json"
    with open(replan_filename, 'w', encoding='utf-8') as f:
        json.dump(replan_spec, f, indent=2, ensure_ascii=False)
    print(f"   âœ“ Saved replan to: {replan_filename}")

    print(f"\n2. Testing improvement measurement...")

    # Simulate improved evaluation after recovery
    improved_evaluation = {
        "scores": {
            "coverage": 4,      # Improved
            "faithfulness": 4,  # Improved
            "balance": 3,       # Improved
            "recency": 3,       # Much improved
            "actionability": 4, # Same
            "readability": 5    # Same
        },
        "priority_fixes": [
            "Minor balance improvements could enhance quality further"
        ],
        "overall_score": 3.8,   # Improved
        "evaluation_summary": "Moderate quality after recovery"
    }

    # Test improvement evaluation
    improvement_analysis = recovery_agent.evaluate_improvement(
        low_quality_evaluation,
        improved_evaluation
    )

    print(f"   âœ“ Overall improvement: {improvement_analysis['overall_improvement']['before']:.1f} â†’ {improvement_analysis['overall_improvement']['after']:.1f} (+{improvement_analysis['overall_improvement']['improvement']:.1f})")
    print(f"   âœ“ Recovery success: {improvement_analysis['success']}")

    # Save improvement analysis
    improvement_filename = f"data/evaluations/improvement_analysis_{timestamp}.json"
    with open(improvement_filename, 'w', encoding='utf-8') as f:
        json.dump(improvement_analysis, f, indent=2, ensure_ascii=False)
    print(f"   âœ“ Saved improvement analysis to: {improvement_filename}")

    print(f"\n3. Demonstrating recovery query targeting...")
    for i, query_spec in enumerate(replan_spec.get('replan', [])[:3]):
        print(f"\n   Recovery Query {i+1}:")
        print(f"     Query: {query_spec['subquery']}")
        print(f"     Rationale: {query_spec['rationale']}")
        print(f"     Operators: {', '.join(query_spec.get('operators', [])[:3])}")
        print(f"     Expected results: {query_spec.get('k', 6)} items")

    print(f"\n4. Testing threshold detection...")

    # Test with high-quality evaluation (should not trigger recovery)
    high_quality_evaluation = {
        "scores": {"coverage": 5, "faithfulness": 5, "balance": 4, "recency": 3, "actionability": 5, "readability": 5},
        "overall_score": 4.5,
        "evaluation_summary": "High quality report"
    }

    no_recovery_plan = recovery_agent.create_replan(
        compression_result,
        high_quality_evaluation,
        query
    )

    print(f"   âœ“ High quality (4.5/5.0): {no_recovery_plan.get('expected_gain', 'No recovery needed')}")
    print(f"   âœ“ Low quality (2.5/5.0): Recovery triggered with {len(replan_spec.get('replan', []))} queries")

    print(f"\n5. Verifying file organization...")

    # Check that files were saved in correct directories
    files_created = [
        replan_filename,
        improvement_filename
    ]

    for filename in files_created:
        if os.path.exists(filename):
            size = os.path.getsize(filename)
            print(f"   âœ“ {filename} ({size} bytes)")
        else:
            print(f"   âœ— {filename} (not found)")

    print(f"\n=== RECOVERY/REPLAN AGENT TESTING COMPLETE ===")
    print("âœ… Recovery threshold detection working")
    print("âœ… Targeted query generation working")
    print("âœ… Improvement measurement working")
    print("âœ… File organization working")
    print("âœ… Complete recovery pipeline verified")

    print(f"\næ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"ðŸ“ æ¢å¤è®¡åˆ’: {replan_filename}")
    print(f"ðŸ“ æ”¹è¿›åˆ†æž: {improvement_filename}")

    return {
        "replan_file": replan_filename,
        "improvement_file": improvement_filename,
        "recovery_triggered": len(replan_spec.get('replan', [])) > 0,
        "improvement_achieved": improvement_analysis['success']
    }

if __name__ == "__main__":
    result = test_complete_recovery_with_files()
    print(f"\næœ€ç»ˆç»“æžœ: {result}")