# 🔬 Deep Research Agent

A comprehensive multi-agent research system built with LangGraph that transforms vague queries into structured, evidence-based research reports. This system implements a 10-phase research pipeline designed for producing decision-grade intelligence with automatic quality assessment and self-healing capabilities.

## 🎯 Overview

Deep Research Agent is an autonomous research system that:
- **Clarifies** vague research questions into structured specifications
- **Plans** comprehensive research strategies with diversified search approaches
- **Collects** evidence from multiple sources with quality scoring
- **Analyzes** conflicts and synthesizes findings
- **Generates** tailored reports for different audiences
- **Evaluates** quality automatically and triggers recovery when needed
- **Routes** between different AI models for cost/quality optimization
- **Monitors** all operations with structured observability

## 🏗️ System Architecture

### Modular Multi-Agent Design

The system follows a clean modular architecture with separated concerns:

```
deep-research-agent/
├── agents/                    # 10 specialized agent classes
│   ├── clarify_agent.py      # Query clarification
│   ├── research_brief_agent.py # Research planning
│   ├── supervisor_planner_agent.py # Search orchestration
│   ├── researcher_agent.py   # Evidence collection
│   ├── compress_conflict_agent.py # Synthesis & conflict analysis
│   ├── report_agent.py       # Report generation
│   ├── evaluator_agent.py    # Quality assessment
│   ├── recovery_replan_agent.py # Self-healing
│   ├── model_router_agent.py # Cost/quality optimization
│   └── observability_agent.py # Audit & monitoring
├── pipeline/                  # Workflow orchestration
│   ├── runner.py             # Main execution pipeline
│   └── __init__.py           # Pipeline exports
├── utils/                     # Shared utilities
│   ├── data_manager.py       # File operations & data persistence
│   └── __init__.py           # Utility exports
└── main.py                   # CLI interface
```

### 10-Phase Research Pipeline

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Phase 1   │───▶│   Phase 2   │───▶│   Phase 3   │───▶│   Phase 4   │───▶│   Phase 5   │
│   Clarify   │    │    Brief    │    │    Plan     │    │  Evidence   │    │  Compress   │
│   Agent     │    │   Agent     │    │   Agent     │    │   Agent     │    │   Agent     │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
                                                                                      │
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  Phase 10   │◀───│   Phase 9   │◀───│   Phase 8   │◀───│   Phase 7   │◀───│   Phase 6   │
│Observability│    │   Router    │    │  Recovery   │    │ Evaluation  │    │   Report    │
│   Agent     │    │   Agent     │    │   Agent     │    │   Agent     │    │   Agent     │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
```

### Agent Responsibilities

| Phase | Agent | Purpose | Input | Output |
|-------|--------|---------|--------|---------|
| 1 | **Clarify Agent** | Transform vague queries into structured research specs | User query | Research specification |
| 2 | **Research Brief Agent** | Create detailed research outlines | Clarified query | Research brief |
| 3 | **Supervisor/Planner Agent** | Decompose into parallel search tasks | Research brief | Search plan |
| 4 | **Researcher Agent** | Execute web searches and extract evidence | Search plan | Evidence collections |
| 5 | **Compress/Conflict Agent** | Synthesize findings and identify conflicts | Evidence | Compressed insights |
| 6 | **Report Agent** | Generate structured, audience-tailored reports | Compressed data | Final report |
| 7 | **Evaluator Agent** | Assess report quality across 6 dimensions | Report + evidence | Quality scores |
| 8 | **Recovery Agent** | Fix quality issues through targeted searches | Low scores | Improved data |
| 9 | **Model Router Agent** | Optimize cost/quality by selecting appropriate models | Query complexity | Model assignments |
| 10 | **Observability Agent** | Generate audit trails and structured logs | Run logs | Audit reports |

## 📁 Data Organization

The project uses a structured data directory for reproducibility and observability:

```
data/
├── runs/                           # Individual research sessions
│   └── YYYY-MM-DD_HH-MM-SS/        # Timestamped run directory
│       ├── clarify.json            # Phase 1: Clarification results
│       ├── brief.md                # Phase 2: Research brief
│       ├── plan.json               # Phase 3: Search plan
│       ├── evidence.jsonl          # Phase 4: Evidence (JSON Lines)
│       ├── compressed.json         # Phase 5: Synthesized insights
│       ├── report.md               # Phase 6: Final report
│       ├── judge.json              # Phase 7: Quality evaluation
│       ├── replan.json             # Phase 8: Recovery plan (if needed)
│       └── logs.ndjson             # Phase 10: Structured logs
├── out/                            # Final exports and deliverables
├── evidence/                       # Aggregated evidence across runs
├── compressed/                     # Synthesized insights repository
├── web_cache/                      # Search and fetch caching
├── observability/                  # Long-term monitoring data
├── seeds/                          # Test queries and configurations
├── whitelist/                      # Trusted source domains
└── blacklist/                      # Blocked source domains
```

## 🚀 Quick Start

### Prerequisites

- Python 3.8+
- Internet connection for web searches

### Installation

```bash
# Clone the repository
git clone https://github.com/HaojingTONG/deep-research-agent.git
cd deep-research-agent

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```bash
# Run a complete research session
python main.py "What are the benefits of exercise?"

# Test specific components
python main.py "AI safety research" --test-researcher
python main.py "Climate change impacts" --test-compress
python main.py "Remote work effectiveness" --test-report
python main.py "Model routing demo" --test-routing
python main.py "Observability demo" --test-observability

# Import agents programmatically
python -c "from agents import ClarifyAgent, ResearcherAgent; agent = ClarifyAgent()"
python -c "from pipeline import run_research_pipeline; run_research_pipeline('test', None)"
```

### Example Output

After running, you'll find:
- **Main report**: `data/runs/YYYY-MM-DD_HH-MM-SS/report.md`
- **Quality assessment**: `data/runs/YYYY-MM-DD_HH-MM-SS/judge.json`
- **Evidence collection**: `data/runs/YYYY-MM-DD_HH-MM-SS/evidence.jsonl`
- **Exported copy**: `data/out/research_report_YYYY-MM-DD_HH-MM-SS.md`

## 🔧 Configuration

### Audience Targeting

Configure target audiences in `data/seeds/audiences.yaml`:

```yaml
audiences:
  executive:
    description: "C-level executives and decision makers"
    output_style: "high-level summary with actionable insights"
    focus: "business impact and strategic recommendations"

  researcher:
    description: "Academic researchers and scientists"
    output_style: "detailed analysis with comprehensive citations"
    focus: "methodology, evidence quality, and knowledge gaps"
```

### Search Quality Control

- **Whitelist**: `data/whitelist/domains.txt` - Trusted academic and news sources
- **Blacklist**: `data/blacklist/domains.txt` - Low-quality or spam domains

## 📊 Quality Assessment

The system evaluates reports across 6 dimensions:

| Dimension | Description | Target Score |
|-----------|-------------|--------------|
| **Coverage** | Comprehensiveness of topic coverage | ≥ 4.0 |
| **Faithfulness** | Accuracy to source material | ≥ 4.5 |
| **Balance** | Multiple perspectives represented | ≥ 3.5 |
| **Recency** | Use of recent sources | ≥ 3.0 |
| **Actionability** | Clear recommendations provided | ≥ 4.0 |
| **Readability** | Clear, well-structured writing | ≥ 4.0 |

Reports scoring below thresholds trigger automatic recovery procedures.

## 🛠️ Development

### Project Structure

```
deep-research-agent/
├── agents/                        # Modular agent implementations
│   ├── __init__.py               # Unified agent imports
│   ├── clarify_agent.py          # Phase 1: Query clarification
│   ├── research_brief_agent.py   # Phase 2: Research planning
│   ├── supervisor_planner_agent.py # Phase 3: Search orchestration
│   ├── researcher_agent.py       # Phase 4: Evidence collection
│   ├── compress_conflict_agent.py # Phase 5: Synthesis & conflicts
│   ├── report_agent.py           # Phase 6: Report generation
│   ├── evaluator_agent.py        # Phase 7: Quality assessment
│   ├── recovery_replan_agent.py  # Phase 8: Self-healing
│   ├── model_router_agent.py     # Phase 9: Cost optimization
│   └── observability_agent.py    # Phase 10: Audit trails
├── pipeline/                      # Workflow orchestration
│   ├── __init__.py               # Pipeline exports
│   └── runner.py                 # Main execution logic
├── utils/                         # Shared utilities
│   ├── __init__.py               # Utility exports
│   └── data_manager.py           # File operations & persistence
├── main.py                        # CLI interface
├── requirements.txt               # Python dependencies
├── data/                          # Data directory (see above)
├── test_*.py                      # Component test scripts
├── demo_*.py                      # Feature demonstrations
└── reorganize_data.py             # Data structure migration script
```

### Key Components

- **Modular Agents**: 10 specialized agents in separate files for maintainability
- **Pipeline Runner**: Centralized workflow orchestration with phase management
- **DataManager**: Handles file operations and timestamped directory structure
- **CLI Interface**: Clean command-line interface with test mode support
- **Caching System**: Web search and content fetch caching
- **Quality Assurance**: Automatic evaluation and recovery
- **Observability**: Structured logging and audit trails

### Testing

```bash
# Test individual components
python test_researcher.py          # Search and evidence extraction
python test_compress.py            # Conflict analysis
python test_report.py              # Report generation
python test_evaluator.py           # Quality assessment
python test_recovery_forced.py     # Recovery mechanisms
python test_model_router.py        # Cost optimization
python test_observability.py       # Audit trail generation

# Demo complete functionality
python demo_observability.py       # Observability features
python demo_model_routing.py       # Model routing strategies

# Test modular architecture
python -c "from agents import *; print('All agents imported successfully')"
python -c "from pipeline import run_research_pipeline; print('Pipeline imported successfully')"
python -c "from utils import DataManager; print('Utils imported successfully')"
```

## 🔍 Features

### ✅ Core Capabilities

- **Multi-source Evidence Collection**: Web search with DuckDuckGo integration
- **Quality Scoring**: 0-5 scale evidence quality assessment
- **Conflict Detection**: Automatic identification of contradictory findings
- **Audience Adaptation**: Reports tailored for executives, researchers, consumers
- **Self-Healing**: Automatic quality improvement through targeted re-search
- **Cost Optimization**: Dynamic model routing based on complexity
- **Full Observability**: Complete audit trails and structured logging
- **Caching**: Efficient web search and content caching
- **Reproducibility**: Timestamped runs with complete data lineage

### 🎯 Advanced Features

- **Template System**: Jinja2-based report generation
- **Schema Validation**: JSON Schema validation for data quality
- **Batch Processing**: Support for multiple queries via `data/seeds/`
- **Error Recovery**: Robust error handling with detailed logging
- **Domain Filtering**: Whitelist/blacklist for source quality control

## 📈 Performance

### Typical Run Metrics

- **Evidence Collection**: 10-50 sources per query
- **Processing Time**: 2-5 minutes for complete pipeline
- **Quality Scores**: Average 4.0/5.0 across dimensions
- **Recovery Rate**: 85% of low-quality reports improved automatically

### Scalability

- **Concurrent Searches**: Parallel subquery processing
- **Caching**: Reduces redundant web requests by 60%
- **Incremental Processing**: Resume from any pipeline stage

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes and add tests
4. Commit with clear messages (`git commit -m 'Add amazing feature'`)
5. Push to the branch (`git push origin feature/amazing-feature`)
6. Open a Pull Request

### Development Guidelines

- Follow PEP 8 style guidelines
- Add tests for new features
- Update documentation for API changes
- Ensure all tests pass before submitting

## 📋 Roadmap

### Planned Features

- [ ] **Vector Database Integration**: ChromaDB for semantic search
- [ ] **Multi-language Support**: Research in Chinese, Spanish, etc.
- [ ] **PDF Processing**: Direct academic paper analysis
- [ ] **API Interface**: REST API for programmatic access
- [ ] **Web Interface**: Browser-based research dashboard
- [ ] **Citation Management**: Automatic bibliography generation
- [ ] **Collaborative Features**: Multi-user research projects

### Integration Opportunities

- [ ] **LangSmith**: Enhanced tracing and debugging
- [ ] **LangServe**: Production deployment capabilities
- [ ] **External APIs**: Google Scholar, PubMed integration
- [ ] **Enterprise Features**: SSO, audit compliance, API quotas

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- **LangGraph**: Multi-agent workflow framework
- **DuckDuckGo**: Privacy-respecting search API
- **Trafilatura**: High-quality web content extraction
- **Jinja2**: Flexible template engine

## 📞 Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/deep-research-agent/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/deep-research-agent/discussions)
- **Documentation**: See `data/README.md` for detailed data structure documentation

---

**⚡ Built for researchers, by researchers. Transform any question into evidence-based intelligence.**
