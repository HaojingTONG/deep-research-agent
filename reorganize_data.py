#!/usr/bin/env python3
"""
é‡æ–°ç»„ç»‡dataç›®å½•ç»“æ„
"""

import os
import shutil
import glob
from datetime import datetime

def create_new_structure():
    """åˆ›å»ºæ–°çš„ç›®å½•ç»“æ„"""

    # æ–°çš„ç›®å½•ç»“æ„
    new_structure = {
        "data/runs": "æŒ‰è¿è¡Œæ‰¹æ¬¡ç»„ç»‡çš„å®Œæ•´ç ”ç©¶ä¼šè¯",
        "data/runs/YYYYMMDD_HHMMSS": "å•æ¬¡å®Œæ•´ç ”ç©¶è¿è¡Œçš„æ‰€æœ‰æ–‡ä»¶",
        "data/archive": "å†å²å’Œå½’æ¡£æ–‡ä»¶",
        "data/archive/YYYY-MM": "æŒ‰æœˆå½’æ¡£çš„æ—§æ–‡ä»¶",
        "data/config": "é…ç½®å’Œæ¨¡æ¿æ–‡ä»¶",
        "data/config/templates": "Jinja2æ¨¡æ¿æ–‡ä»¶",
        "data/config/schemas": "JSON SchemaéªŒè¯æ–‡ä»¶",
        "data/monitoring": "ç³»ç»Ÿç›‘æ§å’Œå¯è§‚æµ‹æ€§",
        "data/monitoring/audit": "å®¡è®¡è¿½è¸ªæŠ¥å‘Š",
        "data/monitoring/metrics": "æ€§èƒ½æŒ‡æ ‡å’Œç»Ÿè®¡",
        "data/monitoring/errors": "é”™è¯¯æ—¥å¿—å’Œå¼‚å¸¸æŠ¥å‘Š",
        "data/temp": "ä¸´æ—¶å’Œæµ‹è¯•æ–‡ä»¶",
        "data/temp/tests": "æµ‹è¯•è¿è¡Œäº§ç”Ÿçš„æ–‡ä»¶",
        "data/temp/demos": "æ¼”ç¤ºå’Œç¤ºä¾‹æ–‡ä»¶"
    }

    # åˆ›å»ºç›®å½•ç»“æ„
    print("ğŸ“ åˆ›å»ºæ–°çš„ç›®å½•ç»“æ„...")
    for path, description in new_structure.items():
        if not path.endswith("YYYY-MM") and not path.endswith("YYYYMMDD_HHMMSS"):
            os.makedirs(path, exist_ok=True)
            print(f"   âœ“ {path} - {description}")

    # åˆ›å»ºç¤ºä¾‹è¿è¡Œç›®å½•
    sample_run = f"data/runs/{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(sample_run, exist_ok=True)
    print(f"   âœ“ {sample_run} - ç¤ºä¾‹è¿è¡Œç›®å½•")

    # åˆ›å»ºç¤ºä¾‹å½’æ¡£ç›®å½•
    sample_archive = f"data/archive/{datetime.now().strftime('%Y-%m')}"
    os.makedirs(sample_archive, exist_ok=True)
    print(f"   âœ“ {sample_archive} - ç¤ºä¾‹å½’æ¡£ç›®å½•")

def migrate_existing_files():
    """è¿ç§»ç°æœ‰æ–‡ä»¶åˆ°æ–°ç»“æ„"""

    print("\nğŸ“¦ è¿ç§»ç°æœ‰æ–‡ä»¶...")

    # è¿ç§»è®¡åˆ’
    migrations = [
        # é…ç½®å’Œæ¨¡æ¿æ–‡ä»¶
        ("data/templates/*", "data/config/templates/"),
        ("data/README.md", "data/config/"),

        # ç›‘æ§å’Œæ—¥å¿—æ–‡ä»¶
        ("data/logs/audit_trail_*", "data/monitoring/audit/"),

        # ä¸´æ—¶å’Œæµ‹è¯•æ–‡ä»¶ (è¯†åˆ«æ¨¡å¼)
        ("data/*/.*demo*", "data/temp/demos/"),
        ("data/*/.*test*", "data/temp/tests/"),

        # å…¶ä»–æ–‡ä»¶ç§»åˆ°temp (ç¨åæ‰‹åŠ¨æ•´ç†)
        ("data/evaluations/*", "data/temp/"),
        ("data/evidence/*", "data/temp/"),
        ("data/intermediate/*", "data/temp/"),
        ("data/reports/*", "data/temp/"),
    ]

    for pattern, destination in migrations:
        source_files = glob.glob(pattern, recursive=True)
        if source_files:
            os.makedirs(destination, exist_ok=True)
            for file_path in source_files:
                if os.path.isfile(file_path):
                    filename = os.path.basename(file_path)
                    dest_path = os.path.join(destination, filename)
                    try:
                        shutil.move(file_path, dest_path)
                        print(f"   âœ“ {file_path} â†’ {dest_path}")
                    except Exception as e:
                        print(f"   âš  {file_path} è¿ç§»å¤±è´¥: {e}")

def create_documentation():
    """åˆ›å»ºæ–°çš„ç›®å½•æ–‡æ¡£"""

    doc_content = """# Deep Research Agent - Data Directory Structure

## ğŸ¯ ç›®å½•è®¾è®¡åŸåˆ™

1. **æŒ‰åŠŸèƒ½åˆ†ç»„**: ä¸åŒç±»å‹çš„æ–‡ä»¶æ”¾åœ¨åŠŸèƒ½ç›¸å…³çš„ç›®å½•ä¸­
2. **æŒ‰æ—¶é—´ç»„ç»‡**: è¿è¡Œæ–‡ä»¶æŒ‰æ—¶é—´æˆ³ç»„ç»‡ï¼Œä¾¿äºè¿½è¸ªå’Œæ¸…ç†
3. **åˆ†ç¦»å…³æ³¨ç‚¹**: é…ç½®ã€ç›‘æ§ã€ä¸´æ—¶æ–‡ä»¶åˆ†åˆ«ç®¡ç†
4. **æ˜“äºå½’æ¡£**: æ”¯æŒå®šæœŸå½’æ¡£å’Œæ¸…ç†å†å²æ–‡ä»¶

## ğŸ“ ç›®å½•ç»“æ„è¯¦è§£

```
data/
â”œâ”€â”€ runs/                           # ç ”ç©¶è¿è¡Œæ–‡ä»¶ (æŒ‰æ‰¹æ¬¡ç»„ç»‡)
â”‚   â”œâ”€â”€ 20250921_191500/           # å•æ¬¡å®Œæ•´ç ”ç©¶è¿è¡Œ
â”‚   â”‚   â”œâ”€â”€ 01_clarified.json      # Phase 1: æ¾„æ¸…ç»“æœ
â”‚   â”‚   â”œâ”€â”€ 02_brief.md             # Phase 2: ç ”ç©¶å¤§çº²
â”‚   â”‚   â”œâ”€â”€ 03_plan.json            # Phase 3: æœç´¢è®¡åˆ’
â”‚   â”‚   â”œâ”€â”€ 04_evidence.json       # Phase 4: è¯æ®æ”¶é›†
â”‚   â”‚   â”œâ”€â”€ 05_compressed.json     # Phase 5: è¯æ®å‹ç¼©
â”‚   â”‚   â”œâ”€â”€ 06_report.md            # Phase 6: æœ€ç»ˆæŠ¥å‘Š
â”‚   â”‚   â”œâ”€â”€ 07_evaluation.json     # Phase 7: è´¨é‡è¯„ä¼°
â”‚   â”‚   â”œâ”€â”€ 08_recovery.json       # Phase 8: æ¢å¤è®¡åˆ’ (å¦‚éœ€è¦)
â”‚   â”‚   â”œâ”€â”€ 09_routing.json        # Phase 9: æ¨¡å‹è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ 10_audit.md             # Phase 10: å®¡è®¡è¿½è¸ª
â”‚   â”‚   â””â”€â”€ meta.json               # è¿è¡Œå…ƒæ•°æ®
â”‚   â””â”€â”€ 20250922_093000/           # å¦ä¸€æ¬¡è¿è¡Œ
â”œâ”€â”€ archive/                        # å†å²å½’æ¡£æ–‡ä»¶
â”‚   â”œâ”€â”€ 2025-09/                   # æŒ‰æœˆå½’æ¡£
â”‚   â”‚   â”œâ”€â”€ completed_runs/        # å·²å®Œæˆçš„è¿è¡Œ
â”‚   â”‚   â”œâ”€â”€ reports/               # å†å²æŠ¥å‘Š
â”‚   â”‚   â””â”€â”€ evaluations/           # å†å²è¯„ä¼°
â”‚   â””â”€â”€ 2025-08/
â”œâ”€â”€ config/                         # é…ç½®å’Œæ¨¡æ¿
â”‚   â”œâ”€â”€ templates/                 # Jinja2æ¨¡æ¿æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ report.md.j2           # æŠ¥å‘Šæ¨¡æ¿
â”‚   â”‚   â”œâ”€â”€ brief.md.j2            # å¤§çº²æ¨¡æ¿
â”‚   â”‚   â””â”€â”€ audit.md.j2            # å®¡è®¡æ¨¡æ¿
â”‚   â”œâ”€â”€ schemas/                   # JSON SchemaéªŒè¯
â”‚   â”‚   â”œâ”€â”€ clarified.schema.json  # æ¾„æ¸…ç»“æœSchema
â”‚   â”‚   â”œâ”€â”€ evidence.schema.json   # è¯æ®æ ¼å¼Schema
â”‚   â”‚   â””â”€â”€ evaluation.schema.json # è¯„ä¼°æ ¼å¼Schema
â”‚   â”œâ”€â”€ settings.json              # ç³»ç»Ÿé…ç½®è®¾ç½®
â”‚   â””â”€â”€ README.md                  # ç›®å½•è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ monitoring/                     # ç³»ç»Ÿç›‘æ§å’Œå¯è§‚æµ‹æ€§
â”‚   â”œâ”€â”€ audit/                     # å®¡è®¡è¿½è¸ª
â”‚   â”‚   â”œâ”€â”€ audit_YYYYMMDD_HHMMSS.md # è¿è¡Œå®¡è®¡æŠ¥å‘Š
â”‚   â”‚   â””â”€â”€ summary_YYYY-MM.md     # æœˆåº¦å®¡è®¡æ±‡æ€»
â”‚   â”œâ”€â”€ metrics/                   # æ€§èƒ½æŒ‡æ ‡
â”‚   â”‚   â”œâ”€â”€ performance_YYYY-MM.json # æœˆåº¦æ€§èƒ½æŒ‡æ ‡
â”‚   â”‚   â”œâ”€â”€ quality_trends.json    # è´¨é‡è¶‹åŠ¿åˆ†æ
â”‚   â”‚   â””â”€â”€ usage_stats.json       # ä½¿ç”¨ç»Ÿè®¡
â”‚   â””â”€â”€ errors/                    # é”™è¯¯å’Œå¼‚å¸¸
â”‚       â”œâ”€â”€ error_log_YYYY-MM.json # æœˆåº¦é”™è¯¯æ—¥å¿—
â”‚       â””â”€â”€ recovery_analysis.json # æ¢å¤åˆ†ææŠ¥å‘Š
â””â”€â”€ temp/                          # ä¸´æ—¶å’Œæµ‹è¯•æ–‡ä»¶
    â”œâ”€â”€ tests/                     # æµ‹è¯•è¿è¡Œæ–‡ä»¶
    â”‚   â”œâ”€â”€ test_researcher_*.json
    â”‚   â”œâ”€â”€ test_compress_*.json
    â”‚   â””â”€â”€ test_*_output.*
    â”œâ”€â”€ demos/                     # æ¼”ç¤ºå’Œç¤ºä¾‹
    â”‚   â”œâ”€â”€ demo_report_*.md
    â”‚   â”œâ”€â”€ sample_evidence.json
    â”‚   â””â”€â”€ example_*.json
    â””â”€â”€ scratch/                   # ä¸´æ—¶å·¥ä½œæ–‡ä»¶
        â”œâ”€â”€ debug_*.log
        â””â”€â”€ temp_*.json
```

## ğŸ·ï¸ æ–‡ä»¶å‘½åè§„èŒƒ

### è¿è¡Œæ–‡ä»¶ (data/runs/YYYYMMDD_HHMMSS/)
- `01_clarified.json` - Phase 1æ¾„æ¸…ç»“æœ
- `02_brief.md` - Phase 2ç ”ç©¶å¤§çº²
- `03_plan.json` - Phase 3æœç´¢è®¡åˆ’
- `04_evidence.json` - Phase 4è¯æ®æ”¶é›†
- `05_compressed.json` - Phase 5è¯æ®å‹ç¼©
- `06_report.md` - Phase 6æœ€ç»ˆæŠ¥å‘Š
- `07_evaluation.json` - Phase 7è´¨é‡è¯„ä¼°
- `08_recovery.json` - Phase 8æ¢å¤è®¡åˆ’ (å¯é€‰)
- `09_routing.json` - Phase 9æ¨¡å‹è·¯ç”±
- `10_audit.md` - Phase 10å®¡è®¡è¿½è¸ª
- `meta.json` - è¿è¡Œå…ƒæ•°æ®å’Œé…ç½®

### ç›‘æ§æ–‡ä»¶
- `audit_20250921_191500.md` - ç‰¹å®šè¿è¡Œçš„å®¡è®¡æŠ¥å‘Š
- `performance_2025-09.json` - æœˆåº¦æ€§èƒ½ç»Ÿè®¡
- `error_log_2025-09.json` - æœˆåº¦é”™è¯¯æ±‡æ€»

### ä¸´æ—¶æ–‡ä»¶
- `test_*_20250921_191500.*` - æµ‹è¯•æ–‡ä»¶ (å¸¦æ—¶é—´æˆ³)
- `demo_*_sample.*` - æ¼”ç¤ºæ–‡ä»¶
- `debug_*.log` - è°ƒè¯•æ—¥å¿—

## ğŸ”„ æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸ

1. **ç”Ÿæˆ**: æ–°æ–‡ä»¶åœ¨ `data/runs/YYYYMMDD_HHMMSS/` ä¸­åˆ›å»º
2. **ä½¿ç”¨**: è¿è¡ŒæœŸé—´çš„æ´»è·ƒæ–‡ä»¶
3. **å½’æ¡£**: å®šæœŸç§»åŠ¨åˆ° `data/archive/YYYY-MM/`
4. **æ¸…ç†**: è¶…è¿‡ä¿ç•™æœŸçš„æ–‡ä»¶å¯ä»¥åˆ é™¤

## ğŸ› ï¸ ç»´æŠ¤æ“ä½œ

### åˆ›å»ºæ–°è¿è¡Œç›®å½•
```bash
mkdir data/runs/$(date +%Y%m%d_%H%M%S)
```

### å½’æ¡£æ—§æ–‡ä»¶ (ä¿ç•™æœ€è¿‘30å¤©)
```bash
find data/runs -type d -mtime +30 -exec mv {} data/archive/$(date +%Y-%m)/ \\;
```

### æ¸…ç†ä¸´æ—¶æ–‡ä»¶
```bash
find data/temp -name "*.log" -mtime +7 -delete
find data/temp -name "debug_*" -mtime +3 -delete
```

### ç”Ÿæˆæœˆåº¦æŠ¥å‘Š
```bash
python -m tools.generate_monthly_summary data/archive/2025-09/
```

## ğŸ“Š ç›®å½•å¤§å°ç®¡ç†

- `runs/`: å½“å‰æ´»è·ƒè¿è¡Œ (å»ºè®®ä¿ç•™æœ€è¿‘30å¤©)
- `archive/`: å†å²æ–‡ä»¶ (æŒ‰éœ€ä¿ç•™ï¼Œå»ºè®®6ä¸ªæœˆ)
- `temp/`: ä¸´æ—¶æ–‡ä»¶ (å»ºè®®7å¤©å†…æ¸…ç†)
- `monitoring/`: ç›‘æ§æ•°æ® (å»ºè®®ä¿ç•™1å¹´)
- `config/`: é…ç½®æ–‡ä»¶ (æ°¸ä¹…ä¿ç•™)

## ğŸ¯ ä½¿ç”¨å»ºè®®

1. **æ—¥å¸¸å¼€å‘**: ä¸»è¦ä½¿ç”¨ `runs/` ç›®å½•
2. **è°ƒè¯•æµ‹è¯•**: ä½¿ç”¨ `temp/tests/` ç›®å½•
3. **æ¼”ç¤ºå±•ç¤º**: ä½¿ç”¨ `temp/demos/` ç›®å½•
4. **æ€§èƒ½åˆ†æ**: æŸ¥çœ‹ `monitoring/metrics/` ç›®å½•
5. **é—®é¢˜æ’æŸ¥**: æ£€æŸ¥ `monitoring/errors/` ç›®å½•
6. **å†å²è¿½æº¯**: æœç´¢ `archive/` ç›®å½•

è¿™ä¸ªç»“æ„æ”¯æŒé«˜æ•ˆçš„å¼€å‘ã€è°ƒè¯•ã€ç›‘æ§å’Œç»´æŠ¤å·¥ä½œæµç¨‹ã€‚
"""

    with open("data/config/README.md", 'w', encoding='utf-8') as f:
        f.write(doc_content)

    print(f"\nğŸ“š æ–‡æ¡£å·²åˆ›å»º: data/config/README.md")

def create_helper_scripts():
    """åˆ›å»ºè¾…åŠ©è„šæœ¬"""

    # åˆ›å»ºè¿è¡Œç®¡ç†è„šæœ¬
    run_manager_script = '''#!/usr/bin/env python3
"""
è¿è¡Œç®¡ç†å·¥å…·
"""

import os
import json
import shutil
from datetime import datetime, timedelta

def create_new_run():
    """åˆ›å»ºæ–°çš„è¿è¡Œç›®å½•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = f"data/runs/{timestamp}"
    os.makedirs(run_dir, exist_ok=True)

    # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    meta = {
        "created": datetime.now().isoformat(),
        "status": "initialized",
        "phases": {},
        "files": [],
        "query": ""
    }

    with open(f"{run_dir}/meta.json", 'w') as f:
        json.dump(meta, f, indent=2)

    print(f"âœ“ åˆ›å»ºæ–°è¿è¡Œç›®å½•: {run_dir}")
    return run_dir

def archive_old_runs(days=30):
    """å½’æ¡£æ—§çš„è¿è¡Œæ–‡ä»¶"""
    cutoff_date = datetime.now() - timedelta(days=days)
    runs_dir = "data/runs"
    archive_dir = f"data/archive/{datetime.now().strftime('%Y-%m')}"

    os.makedirs(archive_dir, exist_ok=True)

    archived_count = 0
    for run_name in os.listdir(runs_dir):
        run_path = os.path.join(runs_dir, run_name)
        if os.path.isdir(run_path):
            # è§£ææ—¶é—´æˆ³
            try:
                run_time = datetime.strptime(run_name, "%Y%m%d_%H%M%S")
                if run_time < cutoff_date:
                    dest_path = os.path.join(archive_dir, run_name)
                    shutil.move(run_path, dest_path)
                    print(f"âœ“ å½’æ¡£: {run_name}")
                    archived_count += 1
            except ValueError:
                continue

    print(f"âœ“ å…±å½’æ¡£ {archived_count} ä¸ªè¿è¡Œç›®å½•")

def cleanup_temp_files(days=7):
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    cutoff_date = datetime.now() - timedelta(days=days)
    temp_dir = "data/temp"

    cleaned_count = 0
    for root, dirs, files in os.walk(temp_dir):
        for file in files:
            file_path = os.path.join(root, file)
            file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
            if file_time < cutoff_date:
                os.remove(file_path)
                cleaned_count += 1

    print(f"âœ“ æ¸…ç†äº† {cleaned_count} ä¸ªä¸´æ—¶æ–‡ä»¶")

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        if sys.argv[1] == "new":
            create_new_run()
        elif sys.argv[1] == "archive":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
            archive_old_runs(days)
        elif sys.argv[1] == "cleanup":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 7
            cleanup_temp_files(days)
    else:
        print("ç”¨æ³•: python run_manager.py [new|archive|cleanup] [days]")
'''

    with open("data/config/run_manager.py", 'w', encoding='utf-8') as f:
        f.write(run_manager_script)

    print(f"ğŸ“œ åˆ›å»ºç®¡ç†è„šæœ¬: data/config/run_manager.py")

def update_main_py():
    """æ›´æ–°main.pyä»¥ä½¿ç”¨æ–°çš„ç›®å½•ç»“æ„"""

    print("\nğŸ”§ éœ€è¦æ‰‹åŠ¨æ›´æ–°main.pyä¸­çš„æ–‡ä»¶è·¯å¾„...")
    print("å°†ä»¥ä¸‹è·¯å¾„æ¨¡å¼æ›´æ–°ä¸ºæ–°ç»“æ„:")
    print("  æ—§: data/reports/research_report_{timestamp}.md")
    print("  æ–°: data/runs/{timestamp}/06_report.md")
    print("  ")
    print("  æ—§: data/evaluations/evaluation_{timestamp}.json")
    print("  æ–°: data/runs/{timestamp}/07_evaluation.json")
    print("  ")
    print("  æ—§: data/intermediate/compression_{timestamp}.json")
    print("  æ–°: data/runs/{timestamp}/05_compressed.json")

def main():
    """ä¸»é‡ç»„å‡½æ•°"""

    print("ğŸ”„ é‡æ–°ç»„ç»‡Dataç›®å½•ç»“æ„")
    print("="*60)

    # 1. åˆ›å»ºæ–°ç»“æ„
    create_new_structure()

    # 2. è¿ç§»ç°æœ‰æ–‡ä»¶
    migrate_existing_files()

    # 3. åˆ›å»ºæ–‡æ¡£
    create_documentation()

    # 4. åˆ›å»ºè¾…åŠ©è„šæœ¬
    create_helper_scripts()

    # 5. æç¤ºæ‰‹åŠ¨æ›´æ–°
    update_main_py()

    print(f"\nâœ… ç›®å½•é‡ç»„å®Œæˆ!")
    print(f"ğŸ“š æŸ¥çœ‹æ–°ç»“æ„è¯´æ˜: data/config/README.md")
    print(f"ğŸ› ï¸ ä½¿ç”¨ç®¡ç†å·¥å…·: python data/config/run_manager.py")

if __name__ == "__main__":
    main()